# deep_learning
I'm collecting all my practice and learning code in this repository.

Working with AI tools: ChatGPT & Microsoft Copilot


---

# üß† Deep Learning Cheat Sheet ‚Äì Classification Focus

---

## ‚úÖ Classification Loss Functions

| Problem Type           | Loss Function                    | Use When‚Ä¶ |
|------------------------|----------------------------------|-----------|
| **Binary**             | `binary_crossentropy`           | 0/1 labels |
|                        | `hinge`, `squared_hinge`        | For SVM-like models |
|                        | `focal_loss`                    | Class imbalance |
| **Multiclass (sparse)**| `sparse_categorical_crossentropy` | Class index (e.g., `3`) |
| **Multiclass (one-hot)**| `categorical_crossentropy`      | One-hot labels |
| **Multi-label**        | `binary_crossentropy`           | Multi-hot vector (e.g., `[0, 1, 0]`) |

---

## ‚öôÔ∏è Optimizers

| Optimizer    | Best For                           | Notes |
|--------------|------------------------------------|-------|
| `SGD`        | Simple tasks, low resource usage   | + momentum helps |
| `RMSprop`    | RNNs, noisy data                   | Adaptive learning |
| `Adam`       | General purpose (default)          | Fast convergence |
| `AdamW`      | LLMs, transformers                 | Adam + weight decay |
| `Adagrad`    | Sparse gradients (NLP)             | Learning rate shrinks over time |
| `Nadam`      | Like Adam + Nesterov momentum      | Stable |

---

## üß™ `model.compile()` ‚Äì Key Parameters

```python
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

| Argument         | Purpose |
|------------------|---------|
| `optimizer`       | Update rule (e.g. `'adam'`, `'sgd'`, `Adam(learning_rate=0.001)`) |
| `loss`            | Training objective (e.g. `'binary_crossentropy'`) |
| `metrics`         | Trackable metrics (e.g. `'accuracy'`, `'precision'`, `'AUC'`) |
| `loss_weights`    | For multi-output models |
| `run_eagerly`     | For debugging, disables tf graph |

---

## üéØ Real-World Applications (w/ Loss + Optimizer)

| Task                        | Loss Function                      | Optimizer |
|-----------------------------|------------------------------------|-----------|
| Image classification (MNIST)| `sparse_categorical_crossentropy` | `adam`    |
| Text sentiment (binary)     | `binary_crossentropy`             | `adam`    |
| Object detection            | `focal_loss`                      | `adam`    |
| Multi-label disease tagging | `binary_crossentropy`             | `adam` or `rmsprop` |
| Class imbalance (fraud)     | `weighted crossentropy` or `focal_loss` | `adam` |

---

## üîß Metrics You Can Use

```python
metrics=['accuracy', 'precision', 'recall', 'AUC']
```

---

## üßë‚Äçüíª Next Steps: Practice Ideas

We‚Äôll tackle 1‚Äì2 problems from each of these:
- ‚úÖ MNIST (already done)
- üì¶ [Kaggle] Fashion MNIST
- üì¶ [Kaggle] Toxic Comment (multi-label)
- üì¶ [Kaggle] Chest X-ray (imbalanced, binary)
- üì¶ [Kaggle] Leaf Classification (multiclass)

---
