{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d7d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671dd03a",
   "metadata": {},
   "source": [
    "The breast cancer dataset is a classic and very easy binary classification dataset.\n",
    "\n",
    "\n",
    "Classes: 2\n",
    "\n",
    "Samples per class: 212(M),357(B)\n",
    "\n",
    "Samples total: 569\n",
    "\n",
    "Dimensionality: 30\n",
    "\n",
    "Features: real, positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea9b8e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (455, 30) y_train shape: (455,)\n",
      "X_test shape: (114, 30) y_test shape: (114,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6285714285714286, 0.6228070175438597)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
    "\n",
    "y_train.sum()/y_train.shape[0], y_test.sum()/y_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33b4b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14596678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 15:02:21.258665: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:21.381604: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:22.594963: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:22.836810: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:23.803816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:23.951416: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:24.055431: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:24.271068: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:24.343645: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:24.419806: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:24.430173: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:24.443170: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:24.443762: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:24.452655: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:24.462553: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:02:24.482539: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = KerasClassifier(model=build_model, verbose=0)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"model__learning_rate\": [0.1, 0.01, 0.001],\n",
    "    \"batch_size\": [16, 32],\n",
    "    \"epochs\": [50]\n",
    "}\n",
    "\n",
    "# GridSearchCV setup\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bfc3d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 32, 'epochs': 50, 'model__learning_rate': 0.01}\n",
      "Best Cross-Val Score: 0.9318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        43\n",
      "           1       1.00      0.89      0.94        71\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.92      0.94      0.93       114\n",
      "weighted avg       0.94      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_result.best_params_)\n",
    "print(\"Best Cross-Val Score: {:.4f}\".format(grid_result.best_score_))\n",
    "\n",
    "# Evaluate on test set\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = (grid_result.best_estimator_.predict(X_test) > 0.5).astype(\"int\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c881a22e",
   "metadata": {},
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12adf91b",
   "metadata": {},
   "source": [
    "Absolutely! The `tuner` in `keras_tuner` is like your **smart assistant for hyperparameter tuning**. It automates the process of searching for the best set of hyperparameters for your model.\n",
    "\n",
    "Let’s break it down clearly:\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 **What does the tuner do?**\n",
    "\n",
    "A `tuner`:\n",
    "\n",
    "1. **Receives a `build_model(hp)` function**  \n",
    "   This function tells the tuner what parts of the model can change (like number of units in a layer, learning rate, etc.).\n",
    "\n",
    "2. **Chooses combinations of hyperparameters**  \n",
    "   Based on the type of tuner (e.g. `RandomSearch`, `Hyperband`, `BayesianOptimization`), it selects a set of hyperparameter values from the defined search space.\n",
    "\n",
    "3. **Trains multiple models**  \n",
    "   For each combination of hyperparameters:\n",
    "   - It builds a model\n",
    "   - Trains it on your training data\n",
    "   - Evaluates it on validation data\n",
    "\n",
    "4. **Tracks the best model**  \n",
    "   It keeps track of:\n",
    "   - The **best model (weights)**  \n",
    "   - The **best combination of hyperparameters**\n",
    "\n",
    "---\n",
    "\n",
    "### 🛠️ **How does it work under the hood (for `RandomSearch`)?**\n",
    "\n",
    "```text\n",
    "→ You define a search space (via hp.Choice, hp.Int, etc.)\n",
    "→ Tuner randomly samples hyperparameters from this space\n",
    "→ Builds and trains the model using those values\n",
    "→ Evaluates on validation set (e.g., using val_accuracy)\n",
    "→ Repeats this for a defined number of trials (max_trials)\n",
    "→ Selects the combination that gave the best result\n",
    "```\n",
    "\n",
    "So in your case with:\n",
    "\n",
    "```python\n",
    "max_trials=10\n",
    "```\n",
    "\n",
    "→ It will try **10 different combinations** of:\n",
    "- `units1`: 16 to 128 (step 16)\n",
    "- `units2`: 8 to 64 (step 8)\n",
    "- `learning_rate`: 0.01, 0.001, 0.0001\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Why is it useful?\n",
    "\n",
    "- You don’t have to manually loop through all combos\n",
    "- It helps avoid underfitting or overfitting\n",
    "- Improves model performance with minimal effort\n",
    "- You can plug it into **any Keras model** with minimal code change\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b073c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from keras-tuner) (3.9.0)\n",
      "Requirement already satisfied: packaging in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from keras-tuner) (24.2)\n",
      "Requirement already satisfied: requests in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from keras-tuner) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from keras->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: numpy in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from keras->keras-tuner) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from keras->keras-tuner) (3.13.0)\n",
      "Requirement already satisfied: optree in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from keras->keras-tuner) (0.14.1)\n",
      "Requirement already satisfied: ml-dtypes in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from requests->keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from requests->keras-tuner) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from requests->keras-tuner) (2025.1.31)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from rich->keras->keras-tuner) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wd/_vtbthvs7szg1hl8nj3sx92w0000gn/T/ipykernel_47757/1660963963.py:2: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "! pip install keras-tuner\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5987162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with Keras Tuner \n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units1', min_value=16, max_value=128, step=16),\n",
    "        activation='relu',\n",
    "        input_shape=(X_train.shape[1],)\n",
    "    ))\n",
    "    \n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units2', min_value=8, max_value=64, step=8),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "    # Tune learning rate\n",
    "    lr = hp.Choice('learning_rate', [0.01, 0.001, 0.0001])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=lr),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2df129e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumitsontakke/Documents/Dev/PES/mlenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Set up RandomSearch Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Try 10 combinations\n",
    "    executions_per_trial=1,\n",
    "    directory='random_search_dir',\n",
    "    project_name='breast_cancer_tuning'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ec503dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.8901098966598511\n",
      "\n",
      "Best val_accuracy So Far: 0.9340659379959106\n",
      "Total elapsed time: 00h 01m 07s\n"
     ]
    }
   ],
   "source": [
    "# Perform Search\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c86c377",
   "metadata": {},
   "source": [
    "🎯 Summary:\n",
    "- The tuner just tries random combinations from the space you define.\n",
    "- For each combo, it builds → trains → evaluates → remembers the best.\n",
    "- You can access the top model and hyperparams after tuning is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e064d909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.01\n",
      "Best units1: 96\n",
      "Best units2: 48\n"
     ]
    }
   ],
   "source": [
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best learning rate:\", best_hp.get('learning_rate'))\n",
    "print(\"Best units1:\", best_hp.get('units1'))\n",
    "print(\"Best units2:\", best_hp.get('units2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6b1ad84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4861 - loss: 69.6144 - val_accuracy: 0.4066 - val_loss: 4.3360\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5588 - loss: 6.7959 - val_accuracy: 0.7253 - val_loss: 1.7698\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7746 - loss: 2.0688 - val_accuracy: 0.8791 - val_loss: 0.6680\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9121 - loss: 0.5685 - val_accuracy: 0.8462 - val_loss: 0.5957\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8924 - loss: 0.6214 - val_accuracy: 0.8462 - val_loss: 0.5322\n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9159 - loss: 0.4699 - val_accuracy: 0.9121 - val_loss: 0.5674\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9095 - loss: 0.4011 - val_accuracy: 0.9121 - val_loss: 0.3787\n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9222 - loss: 0.3393 - val_accuracy: 0.9011 - val_loss: 0.3455\n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9191 - loss: 0.2665 - val_accuracy: 0.7473 - val_loss: 0.8126\n",
      "Epoch 10/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8710 - loss: 0.5065 - val_accuracy: 0.9121 - val_loss: 0.3213\n",
      "Epoch 11/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8994 - loss: 0.3524 - val_accuracy: 0.9121 - val_loss: 0.2505\n",
      "Epoch 12/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9176 - loss: 0.2271 - val_accuracy: 0.9121 - val_loss: 0.2460\n",
      "Epoch 13/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9261 - loss: 0.2395 - val_accuracy: 0.8022 - val_loss: 0.5234\n",
      "Epoch 14/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8573 - loss: 0.4164 - val_accuracy: 0.9121 - val_loss: 0.2462\n",
      "Epoch 15/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9074 - loss: 0.2479 - val_accuracy: 0.8681 - val_loss: 0.4127\n",
      "Epoch 16/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9371 - loss: 0.1928 - val_accuracy: 0.6044 - val_loss: 1.3877\n",
      "Epoch 17/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7300 - loss: 1.0448 - val_accuracy: 0.5275 - val_loss: 2.2019\n",
      "Epoch 18/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7300 - loss: 1.1623 - val_accuracy: 0.7912 - val_loss: 2.5865\n",
      "Epoch 19/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8406 - loss: 1.2776 - val_accuracy: 0.9011 - val_loss: 0.3597\n",
      "Epoch 20/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8606 - loss: 0.5114 - val_accuracy: 0.9121 - val_loss: 0.3534\n",
      "Epoch 21/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8737 - loss: 0.6811 - val_accuracy: 0.8901 - val_loss: 0.5525\n",
      "Epoch 22/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8872 - loss: 0.4603 - val_accuracy: 0.8132 - val_loss: 0.6621\n",
      "Epoch 23/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9230 - loss: 0.3333 - val_accuracy: 0.9121 - val_loss: 0.2835\n",
      "Epoch 24/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9066 - loss: 0.2832 - val_accuracy: 0.9011 - val_loss: 0.3943\n",
      "Epoch 25/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9267 - loss: 0.2605 - val_accuracy: 0.8901 - val_loss: 0.2458\n",
      "Epoch 26/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9356 - loss: 0.1908 - val_accuracy: 0.9231 - val_loss: 0.2378\n",
      "Epoch 27/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9251 - loss: 0.2075 - val_accuracy: 0.9121 - val_loss: 0.2314\n",
      "Epoch 28/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9387 - loss: 0.1732 - val_accuracy: 0.9121 - val_loss: 0.2126\n",
      "Epoch 29/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9325 - loss: 0.1653 - val_accuracy: 0.8681 - val_loss: 0.3788\n",
      "Epoch 30/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9209 - loss: 0.2523 - val_accuracy: 0.9231 - val_loss: 0.2204\n",
      "Epoch 31/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9170 - loss: 0.1959 - val_accuracy: 0.9121 - val_loss: 0.1995\n",
      "Epoch 32/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9408 - loss: 0.1587 - val_accuracy: 0.9451 - val_loss: 0.2532\n",
      "Epoch 33/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9276 - loss: 0.2135 - val_accuracy: 0.9231 - val_loss: 0.1955\n",
      "Epoch 34/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9218 - loss: 0.1769 - val_accuracy: 0.9231 - val_loss: 0.2128\n",
      "Epoch 35/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9053 - loss: 0.2347 - val_accuracy: 0.9011 - val_loss: 0.1811\n",
      "Epoch 36/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9103 - loss: 0.2777 - val_accuracy: 0.9121 - val_loss: 0.2512\n",
      "Epoch 37/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9325 - loss: 0.1903 - val_accuracy: 0.9121 - val_loss: 0.2417\n",
      "Epoch 38/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8857 - loss: 0.3721 - val_accuracy: 0.9121 - val_loss: 0.2454\n",
      "Epoch 39/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9082 - loss: 0.2445 - val_accuracy: 0.9121 - val_loss: 0.2113\n",
      "Epoch 40/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8622 - loss: 0.3751 - val_accuracy: 0.9121 - val_loss: 0.2437\n",
      "Epoch 41/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9043 - loss: 0.2576 - val_accuracy: 0.9121 - val_loss: 0.2571\n",
      "Epoch 42/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9362 - loss: 0.1773 - val_accuracy: 0.9121 - val_loss: 0.2063\n",
      "Epoch 43/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9335 - loss: 0.1626 - val_accuracy: 0.8901 - val_loss: 0.3270\n",
      "Epoch 44/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8943 - loss: 0.1939 - val_accuracy: 0.9121 - val_loss: 0.2184\n",
      "Epoch 45/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9269 - loss: 0.2175 - val_accuracy: 0.9121 - val_loss: 0.1755\n",
      "Epoch 46/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9225 - loss: 0.1784 - val_accuracy: 0.9231 - val_loss: 0.2446\n",
      "Epoch 47/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9183 - loss: 0.1982 - val_accuracy: 0.9121 - val_loss: 0.2035\n",
      "Epoch 48/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9370 - loss: 0.1408 - val_accuracy: 0.9231 - val_loss: 0.1958\n",
      "Epoch 49/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9548 - loss: 0.1196 - val_accuracy: 0.9011 - val_loss: 0.1727\n",
      "Epoch 50/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9288 - loss: 0.1586 - val_accuracy: 0.9341 - val_loss: 0.2097\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9728 - loss: 0.0991 \n",
      "Test accuracy: 0.9736841917037964\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "history = best_model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "# Evaluate on test set\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d908ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
